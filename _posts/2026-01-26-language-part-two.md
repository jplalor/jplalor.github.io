---
title: "Language, Part 2"
---


[A few years ago](https://johnlalor.net/2024/08/language/) I wrote a post musing on the degree to which human interaction with LLMs would impact *human language*. 

With models being shoved in front of everyone everywhere all of the time, there would be certain individuals, professions, etc. who would interact with these models frequently. 
And my proposal was that, if they are having online chat back-and-forths with these models frequently enough, what they see from their conversant might start to bleed into what they say (type).
It turns out that [I was on to something](https://x.com/emollick/status/2014444854265119119) ([Source: The Signal Newsletter](https://thesignal.substack.com/p/docs-decks-and-googles-gift-to-learners)). 
Researchers looked at vocabulary use from YouTube videos and found individuals using a lot of ChatGPT's favorite words. 
Now, the next step is to see if we can identify preferred vocabulary across LLMs, see if they have distinct preferences in vocabulary choice, then compare that to humans to try to "predict" whether they are a ChatGPT, Gemini, etc. user. 

