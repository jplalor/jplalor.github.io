@inproceedings{abbasiConstructingPsychometricTestbed2021,
  title = {Constructing a Psychometric Testbed for Fair Natural Language Processing},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing{\textsuperscript{a}}},
  author = {Abbasi, Ahmed and Dobolyi, David and Lalor, John P and Netemeyer, Richard G and Smith, Kendall and Yang, Yi},
  date = {2021},
  pages = {3748--3758},
  url = {https://aclanthology.org/2021.emnlp-main.304/},
  keywords = {acl,conference},
  note = {Authors listed alphabetically.}
}

@misc{abbasiMoveCastModelingSpatioTemporal,
  title = {{{MoveCast}}: {{Modeling Spatio-Temporal Movements Using Graph Neural Networks}}},
  author = {Abbasi, Ahmed and Ahmad, Faizan and Lalor, John P and Zeng, Daniel},
  keywords = {WP},
  note = {Target: TBD}
}

@inproceedings{berenteIllusionCertaintyDataDriven2021,
  title = {The {{Illusion}} of {{Certainty}} and {{Data-Driven Decision Making}} in {{Emergent Situations}}},
  booktitle = {International {{Conference}} on {{Information Systems}} ({{ICIS}})},
  author = {Berente, Nicholas and Lalor, John P and Somanchi, Sriram and Abbasi, Ahmed},
  date = {2021},
  url = {https://aisel.aisnet.org/icis2021/gen_topics/gen_topics/10/},
  keywords = {conference,nonacl}
}

@misc{chakrabortyExtractingStyleSocial,
  title = {Extracting {{Style}} from {{Social Media Content}} to {{Predict Engagement}}},
  author = {Lalor, John P and Chakraborty, Ishita and Kanuri, Vamsi},
  keywords = {underreview},
  note = {Reject and resubmit at Journal of Marketing Research}
}

@misc{chenAdvancingDesignReputation,
  title = {Advancing the {{Design}} of {{Reputation}} and {{Feedback Systems}} in {{Education}}: {{A Field Experiment}} on {{Multidimensional Ratings}}},
  author = {Chen, Yixing and Costello, John and Lalor, John P and Guo, Robert},
  keywords = {underreview},
  note = {Under review (1st round) at Journal of Marketing. First two authors contributed equally.}
}

@unpublished{chenDetectingHypoglycemiaIncidents2018,
  title = {Detecting {{Hypoglycemia Incidents}} from {{Patients}}' {{Secure Messages}}},
  author = {Chen, Jinying and Lalor, John P and Yu, Hong},
  date = {2018},
  eventtitle = {American Medical Informatics Association ({{AMIA}}) Annual Symposium},
  keywords = {abstract,conference,otherpr},
  note = {American Medical Informatics Association (AMIA) Annual Symposium}
}

@inproceedings{chenDetectingHypoglycemiaIncidents2018a,
  title = {Detecting {{Hypoglycemia Incidents}} from {{Patients}}' {{Secure Messages}}},
  author = {Chen, Jinying and Lalor, John P and Yu, Hong},
  date = {2018},
  keywords = {abstract,conference}
}

@article{chenDetectingHypoglycemiaIncidents2019,
  title = {Detecting {{Hypoglycemia Incidents Reported}} in {{Patients}}' {{Secure Messages}}: {{Using Cost-Sensitive Learning}} and {{Oversampling}} to {{Reduce Data Imbalance}}.},
  author = {Chen, Jinying and Lalor, John P and Liu, Weisong and Druhl, Emily and Granillo, Edgard and Vimalananda, Varsha G. and Yu, Hong},
  date = {2019},
  journaltitle = {Journal of medical Internet research},
  shortjournal = {J Med Internet Res},
  volume = {21},
  number = {3},
  eprint = {30855231},
  eprinttype = {pmid},
  pages = {e11990},
  issn = {1438-8871 1439-4456},
  doi = {10.2196/11990},
  abstract = {BACKGROUND: Improper dosing of medications such as insulin can cause hypoglycemic episodes, which may lead to severe morbidity or even death. Although secure  messaging was designed for exchanging nonurgent messages, patients sometimes  report hypoglycemia events through secure messaging. Detecting these  patient-reported adverse events may help alert clinical teams and enable early  corrective actions to improve patient safety. OBJECTIVE: We aimed to develop a  natural language processing system, called HypoDetect (Hypoglycemia Detector), to  automatically identify hypoglycemia incidents reported in patients' secure  messages. METHODS: An expert in public health annotated 3000 secure message  threads between patients with diabetes and US Department of Veterans Affairs  clinical teams as containing patient-reported hypoglycemia incidents or not. A  physician independently annotated 100 threads randomly selected from this dataset  to determine interannotator agreement. We used this dataset to develop and  evaluate HypoDetect. HypoDetect incorporates 3 machine learning algorithms widely  used for text classification: linear support vector machines, random forest, and  logistic regression. We explored different learning features, including new  knowledge-driven features. Because only 114 (3.80\%) messages were annotated as  positive, we investigated cost-sensitive learning and oversampling methods to  mitigate the challenge of imbalanced data. RESULTS: The interannotator agreement  was Cohen kappa=.976. Using cross-validation, logistic regression with  cost-sensitive learning achieved the best performance (area under the receiver  operating characteristic curve=0.954, sensitivity=0.693, specificity 0.974, F1  score=0.590). Cost-sensitive learning and the ensembled synthetic minority  oversampling technique improved the sensitivity of the baseline systems  substantially (by 0.123 to 0.728 absolute gains). Our results show that a variety  of features contributed to the best performance of HypoDetect. CONCLUSIONS:  Despite the challenge of data imbalance, HypoDetect achieved promising results  for the task of detecting hypoglycemia incidents from secure messages. The system  has a great potential to facilitate early detection and treatment of  hypoglycemia.},
  langid = {english},
  pmcid = {PMC6431826},
  keywords = {*adverse event detection,*drug-related side effects and adverse reactions,*hypoglycemia,*imbalanced data,*natural language processing,*Natural Language Processing,*secure messaging,*supervised machine learning,adverse event detection,drug-related side effects and adverse reactions,Electronic Health Records/*standards,Female,Humans,hypoglycemia,Hypoglycemia/*diagnosis,imbalanced data,journal,Male,natural language processing,secure messaging,Social Media/*standards,supervised machine learning}
}

@unpublished{choEfficientSemiSupervisedLearning2019,
  title = {Efficient {{Semi-Supervised Learning}} for {{Natural Language Understanding}} by {{Optimizing Diversity}}},
  author = {Cho, Eunah and Xie, He and Lalor, John P and Kumar, Varun and Campbell, William M},
  date = {2019},
  url = {https://arxiv.org/abs/1910.04196},
  eventtitle = {{{ASRU}} 2019: The {{IEEE}} Automatic Speech Recognition and Understanding Workshop},
  keywords = {abstract,otherpr,workshop},
  note = {ASRU 2019: the IEEE automatic speech recognition and understanding workshop}
}

@inproceedings{cookNoSimpleAnswer2025,
  title = {No {{Simple Answer}} to {{Data Complexity}}: {{An Examination}} of {{Instance-Level Complexity Metrics}} for {{Classification Tasks}}},
  booktitle = {Proceedings of the 2025 Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics{\textsuperscript{a}}},
  author = {Cook, Ryan and Lalor, John P and Abbasi, Ahmed},
  date = {2025},
  keywords = {acl,conference}
}

@inproceedings{duan2023hcoal,
  title = {H-{{COAL}}: {{Human}} Correction of {{AI-Generated}} Labels for Biomedical Named Entity Recognition},
  booktitle = {Conference on Information Systems and Technology ({{CIST}})},
  author = {Duan, Xiaojing and Lalor, John P},
  date = {2023},
  url = {https://arxiv.org/abs/2311.11981},
  keywords = {conference,nonacl,WP}
}

@misc{duanBiasAheadUnified,
  title = {Bias {{Ahead}}? {{A Unified Bias Analysis Framework}} for {{Transformer-Based Language Models}}},
  author = {Yang, Yi and Duan, Hanyu and Abbasi, Ahmed and Lalor, John P and Tam, Kar Yan},
  url = {https://arxiv.org/abs/2311.10395},
  keywords = {underreview},
  note = {Under review at TrustNLP2025}
}

@inproceedings{lalor-etal-2024-item,
  title = {Item Response Theory for Natural Language Processing},
  booktitle = {Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: {{Tutorial}} Abstracts},
  author = {Lalor, John P and Rodriguez, Pedro and Sedoc, João and Hernandez-Orallo, Jose},
  editor = {Mesgar, Mohsen and Loáiciga, Sharid},
  date = {2024-03},
  pages = {9--13},
  publisher = {Association for Computational Linguistics},
  location = {St. Julian's, Malta},
  url = {https://aclanthology.org/2024.eacl-tutorials.2},
  keywords = {otherpr}
}

@article{lalor2023evaluating,
  ids = {lalorEvaluatingEfficacyNoteAid2023},
  title = {Evaluating the Efficacy of {{NoteAid}} on {{EHR}} Note Comprehension among {{US}} Veterans through Amazon Mechanical Turk},
  author = {Lalor, John P and Wu, Hao and Mazor, Kathleen M and Yu, Hong},
  date = {2023},
  journaltitle = {International Journal of Medical Informatics},
  volume = {172},
  pages = {105006},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/abs/pii/S1386505623000230},
  keywords = {journal}
}

@article{lalor2023py,
  ids = {lalorPyirtScalableItem2022},
  title = {{{py-irt}}: {{A}} Scalable {{Item Response Theory}} Library for {{Python}}},
  author = {Lalor, John P and Rodriguez, Pedro},
  date = {2023},
  journaltitle = {INFORMS Journal on Computing\textsuperscript{a,b}},
  volume = {35},
  number = {1},
  pages = {5--13},
  publisher = {INFORMS},
  url = {https://pubsonline.informs.org/doi/abs/10.1287/ijoc.2022.1250},
  keywords = {journal}
}

@article{lalor2024evaluating,
  title = {Evaluating Expert-Layperson Agreement in Identifying Jargon Terms in Electronic Health Record Notes: {{Observational}} Study},
  author = {Lalor, John P and Levy, David A and Jordan, Harmon S and Hu, Wen and Smirnova, Jenni Kim and Yu, Hong},
  date = {2024},
  journaltitle = {Journal of Medical Internet Research},
  volume = {26},
  pages = {e49704},
  publisher = {JMIR Publications Toronto, Canada},
  url = {https://www.jmir.org/2024/1/e49704},
  keywords = {journal}
}

@inproceedings{lalorBenchmarkingIntersectionalBiases2022,
  title = {Benchmarking Intersectional Biases in {{NLP}}},
  booktitle = {Proceedings of the 2022 Annual Conference of the North American Chapter of the Association for Computational Linguistics{\textsuperscript{a}}},
  author = {Lalor, John P and Yang, Yi and Smith, Kendall and Forsgren, Nicole and Abbasi, Ahmed},
  date = {2022},
  publisher = {Association for Computational Linguistics},
  keywords = {acl,conference}
}

@unpublished{lalorBotsHumansOnline2020,
  title = {Bots versus Humans in Online Social Networks: {{A}} Study of {{Reddit}} Communities},
  author = {Lalor, John P and Berente, Nicholas and Safadi, Hani},
  date = {2020},
  eventtitle = {{{INSNA}} Sunbelt Conference},
  keywords = {abstract,otherpr,workshop},
  note = {INSNA Sunbelt Conference}
}

@inproceedings{lalorBuildingEvaluationScale2016,
  title = {Building an Evaluation Scale Using Item Response Theory},
  booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing. {{Conference}} on Empirical Methods in Natural Language Processing{\textsuperscript{a}}},
  author = {Lalor, John P and Wu, Hao and Yu, Hong},
  date = {2016},
  volume = {2016},
  pages = {648},
  url = {https://aclanthology.org/D16-1062/},
  keywords = {acl,conference}
}

@inproceedings{lalorCIFTCrowdInformedFineTuning2017,
  title = {{{CIFT}}: {{Crowd-Informed Fine-Tuning}} to {{Improve Machine Learning Ability}}},
  booktitle = {Human Computation and Crowdsourcing ({{HCOMP}})},
  author = {Lalor, John P and Wu, Hao and Yu, Hong},
  date = {2017},
  url = {https://arxiv.org/abs/1702.08563v2},
  keywords = {abstract,workshop},
  note = {Human Computation and Crowdsourcing (HCOMP), arXiv preprint arXiv:1702.08563
\par
Human Computation and Crowdsourcing (HCOMP), arXiv preprint arXiv:1702.08563}
}

@unpublished{lalorComparingHumanDNNEnsemble2019,
  title = {Comparing {{Human}} and {{DNN-Ensemble Response Patterns}} for {{Item Response Theory Model Fitting}}},
  author = {Lalor, John P and Wu, Hao and Yu, Hong},
  date = {2019},
  eventtitle = {Workshop on Cognitive Modeling and Computational Linguistics ({{CMCL}})},
  keywords = {abstract,otherpr,workshop},
  note = {Workshop on Cognitive Modeling and Computational Linguistics (CMCL)}
}

@article{lalorComprehENotesInstrumentAssess2018,
  title = {{{ComprehENotes}}, an Instrument to Assess Patient Reading Comprehension of Electronic Health Record Notes: {{Development}} and Validation},
  author = {Lalor, John P and Wu, Hao and Chen, Li and Mazor, Kathleen M and Yu, Hong},
  date = {2018},
  journaltitle = {Journal of Medical Internet Research},
  volume = {20},
  number = {4},
  pages = {e9380},
  url = {https://www.jmir.org/2018/4/e139/},
  keywords = {journal}
}

@unpublished{lalorDoesDefiningMedical2021,
  title = {Does {{Defining Medical Jargon In A Community Hospital Setting Improve Comprehension}}?},
  author = {Lalor, John P and Hu, Wen and Tran, Matthew and Mazor, Kathleen and Yu, Hong},
  date = {2021},
  eventtitle = {{{INFORMS}} Healthcare Conference},
  keywords = {abstract,otherpr,workshop},
  note = {INFORMS Healthcare Conference}
}

@inproceedings{lalorDynamicDataSelection2020,
  title = {Dynamic Data Selection for Curriculum Learning via Ability Estimation},
  booktitle = {Findings of the Association for Computational Linguistics: {{EMNLP}} 2020},
  author = {Lalor, John P and Yu, Hong},
  date = {2020},
  volume = {2020},
  pages = {545},
  url = {https://aclanthology.org/2020.findings-emnlp.48/},
  keywords = {conference,nonacl}
}

@article{lalorEvaluatingEffectivenessNoteAid2021,
  title = {Evaluating the {{Effectiveness}} of {{NoteAid}} in a {{Community Hospital Setting}}: {{Randomized Trial}} of {{Electronic Health Record Note Comprehension Interventions With Patients}}},
  author = {Lalor, John P and Hu, Wen and Tran, Matthew and Wu, Hao and Mazor, Kathleen M and Yu, Hong},
  date = {2021},
  journaltitle = {Journal of Medical Internet Research},
  volume = {23},
  number = {5},
  pages = {e26354},
  url = {https://www.jmir.org/2021/5/e26354/},
  keywords = {journal}
}

@unpublished{lalorGeneratingTestElectronic2017,
  title = {Generating a {{Test}} of {{Electronic Health Record Narrative Comprehension}} with {{Item Response Theory}}},
  author = {Lalor, John P and Wu, Hao and Chen, Li and Mazor, Kathleen and Yu, Hong},
  date = {2017},
  eventtitle = {American Medical Informatics Association ({{AMIA}}) Annual Symposium},
  keywords = {abstract,otherpr,workshop},
  note = {American medical informatics association (AMIA) annual symposium}
}

@article{lalorImprovingElectronicHealth2019,
  title = {Improving Electronic Health Record Note Comprehension with Noteaid: {{Randomized}} Trial of Electronic Health Record Note Comprehension Interventions with Crowdsourced Workers},
  author = {Lalor, John P and Woolf, Beverly and Yu, Hong},
  date = {2019},
  journaltitle = {Journal of Medical Internet Research},
  volume = {21},
  number = {1},
  pages = {e10793},
  url = {https://www.jmir.org/2019/1/e10793/},
  keywords = {journal}
}

@misc{lalorItNotWhat,
  title = {Country-Level Distributed Decoupling: {{Using NLP}} and Machine Learning to Investigate Narrative Divergence Related to {{GDPR}} Enforcement across {{EU}} Countries},
  author = {Lalor, John P and Angst, Corey and Somanchi, Sriram and D'Arcy, John and Nwanganga, Fred},
  keywords = {underreview},
  note = {Major revision (after 1st round) at MIS Quarterly}
}

@unpublished{lalorItNotWhat2024,
  title = {It's {{Not What You Say}}, {{It}}'s {{How You Say It}}: {{How Cultural Dimensions}} Impact {{GDPR Fine Summaries}}},
  author = {Lalor, John P and Angst, Corey and Nwanganga, Fred and D'Arcy, John},
  date = {2024},
  eventtitle = {Academy of Management Annual Meeting},
  keywords = {nonacl,otherpr},
  note = {Academy of management annual meeting}
}

@unpublished{lalorItNotWhat2024b,
  title = {It's {{Not What You Say}}, {{It}}'s {{How You Say It}}: {{How Cultural Dimensions}} Impact {{GDPR Fine Summaries}}},
  author = {Lalor, John P and Angst, Corey and Nwanganga, Fred and D'Arcy, John},
  date = {2024},
  eventtitle = {Twentieth Symposium on Statistical Challenges in Electronic Commerce Research},
  keywords = {nonacl,otherpr},
  note = {Twentieth symposium on statistical challenges in electronic commerce research}
}

@misc{lalorLearningDifficultiesCurriculum,
  title = {A Psychology-Based Unified Dynamic Framework for Curriculum Learning},
  author = {Meng, Guangyu and Zeng, Qingkai and Lalor, John P and Yu, Hong},
  url = {https://arxiv.org/abs/2408.05326},
  keywords = {underreview},
  note = {Under review (1st round) at Computational Linguistics}
}

@unpublished{lalorLearningLatentParameters2019,
  title = {Learning {{Latent Parameters}} without {{Human Response Patterns}}: {{Item Response Theory}} with {{Artificial Crowds}}},
  author = {Lalor, John P and Wu, Hao and Yu, Hong},
  date = {2019},
  eventtitle = {Workshop on Shortcomings in Vision and Language ({{SiVL}})},
  keywords = {abstract,otherpr,workshop},
  note = {Workshop on shortcomings in vision and language (SiVL)}
}

@inproceedings{lalorLearningLatentParameters2019a,
  title = {Learning Latent Parameters without Human Response Patterns: {{Item}} Response Theory with Artificial Crowds},
  booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing. {{Conference}} on Empirical Methods in Natural Language Processing{\textsuperscript{a}}},
  author = {Lalor, John P and Wu, Hao and Yu, Hong},
  date = {2019},
  volume = {2019},
  pages = {4240},
  url = {https://aclanthology.org/D19-1434/},
  keywords = {acl,conference}
}

@misc{lalorMeasuringAlgorithmicInterpretability,
  title = {Measuring Algorithmic Interpretability: {{A}} Human-Learning-Based Framework and the Corresponding Cognitive Complexity Score},
  author = {Lalor, John P and Guo, Hong and Berente, Nicholas and Abbasi, Ahmed and Recker, Jan},
  keywords = {WP},
  note = {Target: Information Systems Research}
}

@unpublished{lalorMeasuringAlgorithmicInterpretability2020,
  title = {Towards {{Measuring Algorithmic Interpretability}}},
  author = {Lalor, John P and Guo, Hong},
  date = {2020},
  eventtitle = {{{INFORMS}} Workshop on Data Science},
  keywords = {abstract,otherpr,workshop},
  note = {INFORMS workshop on data science}
}

@unpublished{lalorMeasuringAlgorithmicInterpretability2021,
  title = {Measuring {{Algorithmic Interpretability}}},
  author = {Lalor, John P and Guo, Hong},
  date = {2021},
  eventtitle = {{{INFORMS}} Annual Meeting},
  keywords = {abstract,otherpr,workshop},
  note = {INFORMS annual meeting}
}

@unpublished{lalorModelingDifficultyUnderstand2018,
  title = {Modeling {{Difficulty}} to {{Understand Deep Learning Performance}}},
  author = {Lalor, John P and Wu, Hao and Yu, Hong},
  date = {2018},
  eventtitle = {Northern Lights Deep Learning Workshop ({{NLDL}})},
  keywords = {abstract,otherpr,workshop},
  note = {Northern lights deep learning workshop (NLDL)}
}

@unpublished{lalorOntheflyDifficultyEstimation2022,
  title = {On-the-Fly {{Difficulty Estimation}} for {{Deep Neural Networks}}},
  author = {Lalor, John P},
  date = {2022},
  eventtitle = {{{INFORMS}} Annual Meeting},
  keywords = {abstract,otherpr,workshop},
  note = {INFORMS annual meeting}
}

@misc{lalorProductionSpreadNews,
  title = {On the {{Production}} and {{Spread}} of {{News}} in a {{Digital Age}}},
  author = {Lalor, John P and Qu, Shawn},
  keywords = {underreview},
  note = {Under review (1st round) at MIS Quarterly}
}

@misc{lalorRankingPRs2023,
  title = {Ranking Pull Requests in Open Source Software},
  author = {Lalor, John P and Just, Rene},
  date = {2023},
  keywords = {nonacl,project},
  note = {Target: Information Systems Research}
}

@unpublished{lalorRankingPullRequests2023,
  title = {Ranking Pull Requests in Open Source Software},
  author = {Lalor, John P},
  date = {2023},
  eventtitle = {Academy of Management Annual Meeting},
  keywords = {nonacl,otherpr},
  note = {Academy of management annual meeting}
}

@article{lalorShouldFairnessBe2024,
  title = {Should {{Fairness}} Be a {{Metric}} or a {{Model}}? {{A Model-based Framework}} for {{Assessing Bias}} in {{Machine Learning Pipelines}}},
  shorttitle = {Should {{Fairness}} Be a {{Metric}} or a {{Model}}?},
  author = {Lalor, John P and Abbasi, Ahmed and Oketch, Kezia and Yang, Yi and Forsgren, Nicole},
  date = {2024-03-22},
  journaltitle = {ACM Trans. Inf. Syst.\textsuperscript{a}},
  volume = {42},
  number = {4},
  pages = {99:1--99:41},
  issn = {1046-8188},
  doi = {10.1145/3641276},
  url = {https://dl.acm.org/doi/10.1145/3641276},
  abstract = {Fairness measurement is crucial for assessing algorithmic bias in various types of machine learning (ML) models, including ones used for search relevance, recommendation, personalization, talent analytics, and natural language processing. However, the fairness measurement paradigm is currently dominated by fairness metrics that examine disparities in allocation and/or prediction error as univariate key performance indicators (KPIs) for a protected attribute or group. Although important and effective in assessing ML bias in certain contexts such as recidivism, existing metrics don’t work well in many real-world applications of ML characterized by imperfect models applied to an array of instances encompassing a multivariate mixture of protected attributes, that are part of a broader process pipeline. Consequently, the upstream representational harm quantified by existing metrics based on how the model represents protected groups doesn’t necessarily relate to allocational harm in the application of such models in downstream policy/decision contexts. We propose FAIR-Frame, a model-based framework for parsimoniously modeling fairness across multiple protected attributes in regard to the representational and allocational harm associated with the upstream design/development and downstream usage of ML models. We evaluate the efficacy of our proposed framework on two testbeds pertaining to text classification using pretrained language models. The upstream testbeds encompass over fifty thousand documents associated with twenty-eight thousand users, seven protected attributes and five different classification tasks. The downstream testbeds span three policy outcomes and over 5.41 million total observations. Results in comparison with several existing metrics show that the upstream representational harm measures produced by FAIR-Frame and other metrics are significantly different from one another, and that FAIR-Frame’s representational fairness measures have the highest percentage alignment and lowest error with allocational harm observed in downstream applications. Our findings have important implications for various ML contexts, including information retrieval, user modeling, digital platforms, and text classification, where responsible and trustworthy AI is becoming an imperative.},
  keywords = {journal},
  file = {/home/lalor/Zotero/storage/XXGN5PWZ/Lalor et al_2024_Should Fairness be a Metric or a Model.pdf}
}

@unpublished{lalorSoftLabelMemorizationGeneralization2018,
  title = {Soft {{Label Memorization-Generalization}} for {{Natural Language Inference}}},
  author = {Lalor, John P and Wu, Hao and Yu, Hong},
  date = {2018},
  url = {https://arxiv.org/abs/1702.08563v3},
  eventtitle = {{{UAI}} Workshop on Uncertainty in Deep Learning},
  keywords = {abstract,otherpr,workshop},
  note = {UAI workshop on uncertainty in deep learning}
}

@inproceedings{lalorUnderstandingDeepLearning2018,
  title = {Understanding Deep Learning Performance through an Examination of Test Set Difficulty: {{A}} Psychometric Case Study},
  booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing. {{Conference}} on Empirical Methods in Natural Language Processing{\textsuperscript{a}}},
  author = {Lalor, John P and Wu, Hao and Munkhdalai, Tsendsuren and Yu, Hong},
  date = {2018},
  volume = {2018},
  pages = {4711},
  url = {https://aclanthology.org/D18-1500/},
  keywords = {acl,conference}
}

@article{levyIndividualFactorsThat2024,
  title = {Individual Factors That Affect Laypeople's Understanding of Definitions of Medical Jargon},
  author = {Levy, David A and Jordan, Harmon S and Lalor, John P and Smirnova, Jenni Kim and Hu, Wen and Liu, Weisong and Yu, Hong},
  date = {2024-12-01},
  journaltitle = {Health Policy and Technology},
  shortjournal = {Health Policy and Technology},
  volume = {13},
  number = {6},
  pages = {100932},
  issn = {2211-8837},
  doi = {10.1016/j.hlpt.2024.100932},
  url = {https://www.sciencedirect.com/science/article/pii/S2211883724000959},
  abstract = {Objective Patients have difficulty understanding medical jargon in electronic health record (EHR) notes. Lay definitions can improve patient comprehension, which is the goal of the NoteAid project. We assess whether the NoteAid definitions are understandable to laypeople and whether understandability differs with respect to layperson characteristics. Methods Definitions for jargon terms were written for laypersons with a 4th-to-7th-grade reading level. 300 definitions were randomly sampled from a corpus of approximately 30,000 definitions. 280 laypeople (crowdsource workers) were recruited; each layperson rated the understandability of 20 definitions. Understandability was rated on a 5-point scale. Using a generalized estimating equation model (GEE) we analyzed the relationship between understandability and age, sex, race/ethnicity, education level, native language, health literacy, and definition writer. Results Overall, 81.1 \% (95 \% CI: 76.5–85.7 \%) of the laypeople reported that the definitions were understandable. Males were less likely to report understanding the definitions than females (OR: 0.73, 95 \% CI: 0.63–0.84). Asians, Hispanics, and those who marked their race/ethnicity as “other” were more likely to report understanding the definitions than whites (Asians: OR: 1.43, 95 \% CI: 1.17–1.73; Hispanics: OR: 1.86, 95 \% CI: 1.33–2.59; Other: OR: 2.48, 95 \% CI: 1.65–3.74). Laypeople whose native language was not English were less likely to report understanding the definitions (OR: 0.51, 95 \% CI: 0.36–0.74). Laypeople with lower health literacy were less likely to report understanding definitions (health literacy score 3: OR: 0.51, 95 \% CI: 0.43–0.62; health literacy score 4: OR: 0.40, 95 \% CI: 0.29–0.55). Conclusion Understandability of definitions among laypeople was high. There were statistically significant race/ethnic differences in self-reported understandability, even after controlling for multiple demographics. Public interest summary We conducted a study to ensure that definitions written for the NoteAid EHR jargon identification tool are understandable. We recruited a diverse group of crowdsource workers and found that overall, the definitions were understandable, but understanding levels varied based on several demographic characteristics.},
  keywords = {Electronic health records,Health informatics,Health literacy,Jargon identification,journal},
  file = {/home/lalor/Zotero/storage/QHQ8KXGC/S2211883724000959.html}
}

@inproceedings{li2024stars,
  title = {Stars Are All You Need: A Distantly Supervised Pyramid Network for Unified Sentiment Analysis},
  booktitle = {Proceedings of the Ninth Workshop on Noisy and User-Generated Text (w-{{NUT}} 2024)},
  author = {Li, Wenchang and Chen, Yixing and Zheng, Shuang and Wang, Lei and Lalor, John P},
  date = {2024},
  pages = {104--118},
  url = {https://aclanthology.org/2024.wnut-1.10/},
  keywords = {abstract,workshop}
}

@online{lim2024large,
  title = {Large Language Model-Based Role-Playing for Personalized Medical Jargon Extraction},
  author = {Lim, Jung Hoon and Kwon, Sunjae and Yao, Zonghai and Lalor, John P and Yu, Hong},
  date = {2024},
  url = {https://arxiv.org/abs/2408.05555},
  pubstate = {prepublished},
  keywords = {WP}
}

@misc{liStarsInsightsExploration,
  title = {From {{Stars}} to {{Insights}}: {{Exploration}} and {{Implementation}} of {{Unified Sentiment Analysis}} with {{Distant Supervision}}},
  author = {Li, Wenchang and Lalor, John P and Chen, Yixing and Kanuri, Vamsi},
  keywords = {underreview},
  note = {Under review (1st round) at ACM Transactions on Management Information Systems}
}

@inproceedings{maEmpiricalAnalysisHumanBot2020,
  title = {An {{Empirical Analysis}} of {{Human-Bot Interaction}} on {{Reddit}}},
  booktitle = {Proceedings of the {{Sixth Workshop}} on {{Noisy User-generated Text}} ({{W-NUT}} 2020)},
  author = {Ma, Ming-Cheng and Lalor, John P.},
  date = {2020-11},
  pages = {101--106},
  publisher = {Association for Computational Linguistics},
  location = {Online},
  doi = {10.18653/v1/2020.wnut-1.14},
  url = {https://aclanthology.org/2020.wnut-1.14},
  urldate = {2021-09-28},
  abstract = {Automated agents (“bots”) have emerged as an ubiquitous and influential presence on social media. Bots engage on social media platforms by posting content and replying to other users on the platform. In this work we conduct an empirical analysis of the activity of a single bot on Reddit. Our goal is to determine whether bot activity (in the form of posted comments on the website) has an effect on how humans engage on Reddit. We find that (1) the sentiment of a bot comment has a significant, positive effect on the subsequent human reply, and (2) human Reddit users modify their comment behaviors to overlap with the text of the bot, similar to how humans modify their text to mimic other humans in conversation. Understanding human-bot interactions on social media with relatively simple bots is important for preparing for more advanced bots in the future.},
  eventtitle = {{{EMNLP-WNUT}} 2020},
  keywords = {abstract,nonacl,workshop},
  note = {Workshop on Noisy User-generated Text (W-NUT)},
  file = {/home/lalor/Zotero/storage/PHA64J36/Ma_Lalor_2020_An Empirical Analysis of Human-Bot Interaction on Reddit.pdf}
}

@inproceedings{millerLearningObjectorientedProgramming2015,
  title = {Learning Object-Oriented Programming in Python: {{Towards}} an Inventory of Difficulties and Testing Pitfalls},
  booktitle = {Proceedings of the 16th Annual Conference on Information Technology Education},
  author = {Miller, Craig and Settle, Amber and Lalor, John P},
  date = {2015},
  url = {https://dl.acm.org/doi/10.1145/2808006.2808017},
  keywords = {conference,nonacl}
}

@misc{mohlmannInflationReputationSystems,
  title = {Inflation in Reputation Systems? {{Newcomers}}, Veterans, and Socialization into a Platform Context},
  author = {Mohlmann, Mareike and Lalor, John P and Son, Yoon and Berente, Nicholas},
  keywords = {underreview},
  note = {Major revision (after 3rd round) at Information Systems Research}
}

@unpublished{munkhdalaiCitationAnalysisNeural2016,
  title = {Citation {{Analysis}} with {{Neural Attention Models}}},
  author = {Munkhdalai, Tsendsuren and Lalor, John P and Yu, Hong},
  date = {2016},
  url = {https://aclanthology.org/W16-6109/},
  eventtitle = {Workshop on Health Text Mining and Information Analysis},
  keywords = {abstract,otherpr,workshop},
  note = {Workshop on Health Text Mining and Information Analysis}
}

@misc{oketchBridgingLLMAccessibility,
  title = {Bridging the {{LLM Accessibility Divide}}? {{Performance}}, {{Fairness}}, and {{Cost}} of {{Closed}} versus {{Open Models}} for {{Automated Essay Scoring}}},
  author = {Oketch, Kezia and Lalor, John P and Yang, Yi and Abbasi, Ahmed},
  keywords = {WP}
}

@misc{pratGALEALeveragingGenerative,
  title = {{{GALEA}} – {{Leveraging Generative Agents}} in {{Artifact Evaluation}}},
  author = {Prat, Nicolas and Lalor, John P and Abbasi, Ahmed},
  keywords = {underreview},
  note = {Under review at DESRIST 2025 (Design Science Research in Information Systems and Technology)}
}

@inproceedings{rodriguez2022clustering,
  title = {Clustering Examples in Multi-Dataset Benchmarks with Item Response Theory},
  booktitle = {Proceedings of the Third Workshop on Insights from Negative Results in {{NLP}}},
  author = {Rodriguez, Pedro and Htut, Phu Mon and Lalor, John P and Sedoc, João},
  date = {2022},
  pages = {100--112},
  url = {https://aclanthology.org/2022.insights-1.14/},
  keywords = {abstract,workshop}
}

@inproceedings{rodriguezEvaluationExamplesAre2021,
  title = {Evaluation Examples Are Not Equally Informative: {{How}} Should That Change {{NLP}} Leaderboards?},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: {{Long}} Papers){\textsuperscript{a}}},
  author = {Rodriguez, Pedro and Barrow, Joe and Hoyle, Alexander Miserlis and Lalor, John P and Jia, Robin and Boyd-Graber, Jordan},
  date = {2021},
  pages = {4486--4503},
  url = {https://aclanthology.org/2021.acl-long.346/},
  keywords = {acl,conference}
}

@article{safadiEffectBotsHuman,
  title = {The {{Effect}} of {{Bots}} on {{Human Interaction}} in {{Online Communities}}},
  author = {Safadi, Hani and Lalor, John P and Berente, Nicholas},
  date = {2024},
  journaltitle = {MIS Quarterly\textsuperscript{a,b}},
  volume = {48},
  number = {3},
  pages = {1279--1295},
  issn = {02767783},
  url = {https://aisel.aisnet.org/misq/vol48/iss3/15/},
  abstract = {We investigate how bots influence human-to-human interaction in online communities. In doing so, we distinguish between reflexive and supervisory bots delegated by community participants and moderators, respectively. We hypothesize that reflexive bot activity will reduce direct reciprocity and increase generalized reciprocity and that supervisory bot activity will reduce preferential attachment among human participants. Through an analysis of almost 70 million posts on the discussion communities on Reddit, a popular platform for online discussions, we found support for the hypotheses. [ABSTRACT FROM AUTHOR]},
  keywords = {agentic artifacts,bots,Chatbots,direct reciprocity,generalized reciprocity,Intelligent agents,journal,network exchange,Online communities,panel vector autoregression,preferential attachment,Reciprocity (Psychology),Reddit (Web resource),reflexive bots,Social interaction,supervisory bots,Virtual communities},
  file = {/home/lalor/Zotero/storage/CCE5JRV4/Safadi et al_2024_The Effect of Bots on Human Interaction in Online Communities.pdf}
}

@inproceedings{safadiEffectBotsHuman2021,
  title = {The {{Effect}} of {{Bots}} on {{Human Interaction}} in {{Online Communities}}},
  booktitle = {International {{Conference}} on {{Information Systems}} ({{ICIS}})},
  author = {Safadi, Hani and Lalor, John P and Berente, Nicholas},
  date = {2021},
  url = {https://aisel.aisnet.org/icis2021/ai_business/ai_business/1/},
  keywords = {conference,nonacl}
}

@inproceedings{settleComputerScienceLinkedcourses2015,
  title = {A Computer Science Linked-Courses Learning Community},
  booktitle = {Proceedings of the 2015 {{ACM}} Conference on Innovation and Technology in Computer Science Education},
  author = {Settle, Amber and Lalor, John P and Steinbach, Theresa},
  date = {2015},
  pages = {123--128},
  url = {https://dl.acm.org/doi/10.1145/2729094.2742621},
  keywords = {conference,nonacl}
}

@inproceedings{settleEvaluatingLinkedcoursesLearning2015,
  title = {Evaluating a Linked-Courses Learning Community for Development Majors},
  booktitle = {Proceedings of the 16th Annual Conference on Information Technology Education},
  author = {Settle, Amber and Lalor, John P and Steinbach, Theresa},
  date = {2015},
  pages = {127--132},
  url = {https://dl.acm.org/doi/10.1145/2808006.2808031},
  keywords = {conference,nonacl}
}

@inproceedings{settleReconsideringImpactCS12015,
  title = {Reconsidering the Impact of {{CS1}} on Novice Attitudes},
  booktitle = {Proceedings of the 46th {{ACM}} Technical Symposium on Computer Science Education},
  author = {Settle, Amber and Lalor, John P and Steinbach, Theresa},
  date = {2015},
  pages = {229--234},
  url = {https://dl.acm.org/doi/10.1145/2676723.2677235},
  keywords = {conference,nonacl}
}

@article{wowakBusinessAnalyticsHealthcare2023,
  title = {Business {{Analytics}} in {{Healthcare}}: {{Past}}, {{Present}}, and {{Future Trends}}},
  shorttitle = {Business {{Analytics}} in {{Healthcare}}},
  author = {Wowak, Kaitlin D and Lalor, John P and Somanchi, Sriram and Angst, Corey M},
  date = {2023-05},
  journaltitle = {Manufacturing \& Service Operations Management\textsuperscript{a,b}},
  shortjournal = {M\&SOM},
  volume = {25},
  number = {3},
  pages = {975--995},
  publisher = {INFORMS},
  issn = {1523-4614},
  doi = {10.1287/msom.2023.1192},
  url = {https://pubsonline.informs.org/doi/full/10.1287/msom.2023.1192},
  abstract = {Problem definition: Business analytics (BA) in healthcare research offers numerous valuable insights that can enhance patient care and hospital performance. Consequently, there has been a rapid surge of research in this area. Academic/practical relevance: The objective of this study is to provide a data-driven summary of the extant BA in healthcare literature and a guide for future research. Methodology: Leveraging a topic modeling technique and network analysis, we provide insight into how BA topics change over time. Results: We provide an in-depth analysis of 320 articles from the University of Texas at Dallas journal list and a basic topic model and network analyses for an additional 6,515 relevant articles from PubMed published in top-tier journals across 69 medical subcategories. Our study bridges research in operations management, information systems, healthcare, and analytics by providing a definition of BA in healthcare and a road map for future research. Managerial implications: Our study provides a single source of information into operations- and analytics-related issues, such as wait times, admissions, hospital performance, etc., that scholars and administrators might use to rethink how specific processes are handled in hospitals. In addition, this work highlights how operations management research has addressed clinically important issues such as patient satisfaction, doctor ratings, readmission rates, mortality, efficiency, cost of care, and compliance with protocols of care, as all are represented in our sample. Another key contribution of our study is that we provide an interactive article analysis tool as a web application for scholars in hopes of facilitating research in this area. Supplemental Material: The e-companion is available at https://doi-org.proxy.library.nd.edu/10.1287/msom.2023.1192.},
  keywords = {analytics,business analytics,healthcare,journal,literature review,web application},
  file = {/home/lalor/Zotero/storage/2NDCN6G7/Wowak et al_2023_Business Analytics in Healthcare.pdf}
}

@online{yangBiasAheadAnalyzing2023,
  title = {Bias {{A-head}}? {{Analyzing Bias}} in {{Transformer-Based Language Model Attention Heads}}},
  shorttitle = {Bias {{A-head}}?},
  author = {Yang, Yi and Duan, Hanyu and Abbasi, Ahmed and Lalor, John P. and Tam, Kar Yan},
  date = {2023-11-17},
  eprint = {2311.10395},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.10395},
  url = {http://arxiv.org/abs/2311.10395},
  urldate = {2024-04-24},
  abstract = {Transformer-based pretrained large language models (PLM) such as BERT and GPT have achieved remarkable success in NLP tasks. However, PLMs are prone to encoding stereotypical biases. Although a burgeoning literature has emerged on stereotypical bias mitigation in PLMs, such as work on debiasing gender and racial stereotyping, how such biases manifest and behave internally within PLMs remains largely unknown. Understanding the internal stereotyping mechanisms may allow better assessment of model fairness and guide the development of effective mitigation strategies. In this work, we focus on attention heads, a major component of the Transformer architecture, and propose a bias analysis framework to explore and identify a small set of biased heads that are found to contribute to a PLM's stereotypical bias. We conduct extensive experiments to validate the existence of these biased heads and to better understand how they behave. We investigate gender and racial bias in the English language in two types of Transformer-based PLMs: the encoder-based BERT model and the decoder-based autoregressive GPT model. Overall, the results shed light on understanding the bias behavior in pretrained language models.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {/home/lalor/Zotero/storage/LVFP7AAC/Yang et al_2023_Bias A-head.pdf;/home/lalor/Zotero/storage/KRHL4WJ2/2311.html}
}

@article{yangHierarchicalDeepDocument2025,
  title = {Hierarchical {{Deep Document Model}}},
  author = {Yang, Yi and Lalor, John P and Abbasi, Ahmed and Zeng, Daniel Dajun},
  date = {2025-01},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering\textsuperscript{a}},
  volume = {37},
  number = {1},
  pages = {351--364},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2024.3487523},
  url = {https://ieeexplore.ieee.org/abstract/document/10737364?casa_token=pQ38D2xZglgAAAAA:xPVoPxEXxoBIKvJX022fESoPAcj5VKNFm16FpLvfMiHrHeiRbkXAmY7_8hkgSk26L4uiRql19c4},
  abstract = {Topic modeling is a commonly used text analysis tool for discovering latent topics in a text corpus. However, while topics in a text corpus often exhibit a hierarchical structure (e.g., cellphone is a sub-topic of electronics), most topic modeling methods assume a flat topic structure that ignores the hierarchical dependency among topics, or utilize a predefined topic hierarchy. In this work, we present a novel Hierarchical Deep Document Model (HDDM) to learn topic hierarchies using a variational autoencoder framework. We propose a novel objective function, sum of log likelihood, instead of the widely used evidence lower bound, to facilitate the learning of hierarchical latent topic structure. The proposed objective function can directly model and optimize the hierarchical topic-word distributions at all topic levels. We conduct experiments on four real-world text datasets to evaluate the topic modeling capability of the proposed HDDM method compared to state-of-the-art hierarchical topic modeling benchmarks. Experimental results show that HDDM achieves considerable improvement over benchmarks and is capable of learning meaningful topics and topic hierarchies. To further demonstrate the practical utility of HDDM, we apply it to a real-world medical notes dataset for clinical prediction. Experimental results show that HDDM can better summarize topics in medical notes, resulting in more accurate clinical predictions.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  keywords = {Accuracy,Analytical models,Benchmark testing,Context modeling,Data models,Deep learning,hierarchical modeling,hierarchical neural topic model,journal,Linear programming,Neural networks,Predictive models,Reviews,Stacking,textual analysis,topic modeling},
  file = {/home/lalor/Zotero/storage/UGZAYCHV/Yang et al_2025_Hierarchical Deep Document Model.pdf;/home/lalor/Zotero/storage/MVF24GHQ/10737364.html}
}

@misc{zhaoLearningCurvePredicting,
  title = {Learning from the {{Curve}}: {{Predicting Successful Projects}} Using {{Functional PCA}}},
  author = {Zhao, Zifeng and Qu, Shawn and Lalor, John P and Abbasi, Ahmed},
  keywords = {project},
  note = {Target: Information Systems Research}
}

@misc{zhengMatthew,
  title = {The Matthew Effect in Recommender Systems: {{Dynamics}}, Methodology, and Impact},
  author = {Zheng, Shuang and Lalor, John P and Chen, Yixing and Wang, Lei},
  keywords = {WP}
}
